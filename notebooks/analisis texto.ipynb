{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de archivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = path.dirname(\".\")\n",
    "\n",
    "# Read the whole text.\n",
    "text = open(path.join(d, 'Don Quijote, by Miguel de Cervantes Saavedra.txt'), encoding=\"utf8\").read()\n",
    "stop_words = open(path.join(d, 'spanish.txt'), encoding=\"utf8\").read()\n",
    "\n",
    "# stop words url: https://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import string\n",
    "\n",
    "filtered_text = text\n",
    "\n",
    "filtered_text = filtered_text.split(\"*** START OF THIS PROJECT GUTENBERG EBOOK DON QUIJOTE ***\")[1]\n",
    "filtered_text = filtered_text.split(\"*** END OF THIS PROJECT GUTENBERG EBOOK DON QUIJOTE ***\")[0]\n",
    "\n",
    "# lower to get better comparison\n",
    "filtered_text = filtered_text.lower()\n",
    "stop_words = stop_words.lower()\n",
    "\n",
    "# added punctuation symbols used in spanish\n",
    "punctuation = punctuation + '¿¡'\n",
    "\n",
    "# apply filters\n",
    "filtered_text = ''.join(c for c in filtered_text if c not in punctuation)\n",
    "filtered_text = ' '.join([word for word in filtered_text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Palabras mas frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quijote', 2176),\n",
       " ('sancho', 2148),\n",
       " ('dijo', 1807),\n",
       " ('señor', 1063),\n",
       " ('respondió', 1062),\n",
       " ('así', 1061),\n",
       " ('merced', 899),\n",
       " ('pues', 862),\n",
       " ('sino', 694),\n",
       " ('caballero', 661),\n",
       " ('decir', 578),\n",
       " ('hacer', 535),\n",
       " ('dios', 531),\n",
       " ('aunque', 530),\n",
       " ('aquí', 516),\n",
       " ('señora', 515),\n",
       " ('aquel', 487),\n",
       " ('mal', 459),\n",
       " ('cosa', 447),\n",
       " ('buen', 442)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(filtered_text.split()).most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800,height=400,max_font_size=80,background_color=\"white\",max_words=500,colormap=\"ocean\").generate(filtered_text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"gaussian\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de palabras en texto filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_text.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cantidad de caracteres en texto filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Comparación de wordcloud limpiando texto con textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "import textacy.datasets\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy_text = text\n",
    "\n",
    "textacy_text = textacy_text.split(\"*** START OF THIS PROJECT GUTENBERG EBOOK DON QUIJOTE ***\")[1]\n",
    "textacy_text = textacy_text.split(\"*** END OF THIS PROJECT GUTENBERG EBOOK DON QUIJOTE ***\")[0]\n",
    "\n",
    "textacy_text = textacy.preprocess.normalize_whitespace(textacy_text)\n",
    "\n",
    "textacy_text = ' '.join([word for word in textacy_text.split() if word not in STOP_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(textacy_text.split()).most_common()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy_text=textacy.preprocess.preprocess_text(textacy_text, fix_unicode=True, lowercase=True, transliterate=False, no_urls=True, no_emails=True, no_phone_numbers=True, no_numbers=False, no_currency_symbols=True, no_punct=True, no_contractions=True, no_accents=True)\n",
    "\n",
    "wordcloud = WordCloud(width=800,height=400,max_font_size=80,background_color=\"white\",max_words=500,colormap=\"ocean\").generate(textacy_text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"gaussian\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de palabras en texto filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(textacy_text.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cantidad de caracteres en texto filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(textacy_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de personajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es')\n",
    "doc = nlp(textacy_text[:20000])\n",
    "print('Name Entity: {0}'.format(doc.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizó el análisis del libro Don Quijote obtenido en formato txt desde la web de Proyecto Gutenber. Iniciamos la curación del archivo importado eliminando el texto agregado por esta web para no interferir con el resultado del análisis y se analizó cantidad de caracteres y palabras resultantes despues de sanitizar el texto manualmente (convierte a minúsculas y remueve puntuación y stopWords) y usando la libreria textacy.\n",
    "Luego de esto se analizaron las palabras mas frecuentes a los string resultantes de cada análisis y se graficó un wordcloud.\n",
    "Resulta interesante ver que el texto resultan de la librería textacy, aun filtrando stopwords y signos de puntación considera palabras que no resultan relevantes para el análisis, pero resulta mas eficiente ya que procesa mas palabras en un tiempo menor. Por esto, se debe analizar su utilización para curación de texto dependiendo del análisis a realizar.\n",
    "Con respecto a la extracción de personajes, no logramos ejecutar las sentencias necesarias en docker con el texto completo ya que la librería no permite la cantidad de caracteres total del texto, por lo que se decidió reducir este análisis a 20000 caracteres iniciales del libro, pero no se pudo obrtener resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
